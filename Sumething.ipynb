{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72d51c9",
   "metadata": {},
   "source": [
    "# Assignment 1, Predictive Methods - AVTEK 2025 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef167d0e",
   "metadata": {},
   "source": [
    "Participants names and contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10c623",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6da701",
   "metadata": {},
   "source": [
    "### 1.1 Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617304d9",
   "metadata": {},
   "source": [
    "**Dataset & suitability for kNN (meets 2/2 points criteria)**  \n",
    "- **Dataset:** Wine Quality (WineQT.csv) from Kaggle.  \n",
    "- **Target (y):** `quality` (discrete score → use as classification label).  \n",
    "- **Why suitable for kNN:**  \n",
    "  - All predictors are **numeric**, enabling distance-based learning.  \n",
    "  - Dataset size is moderate → kNN is computationally feasible.  \n",
    "  - Clear supervised task with a labeled target.  \n",
    "- **What is scikit-learn:** Python ML toolkit providing ready-to-use models (e.g., `KNeighborsClassifier`), utilities (`train_test_split`) and metrics (`accuracy_score`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3aa2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and define X, y (place WineQT.csv next to this notebook)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('WineQT.csv')  # adjust path if needed, e.g., 'data/WineQT.csv'\n",
    "X = df.drop(['quality','Id'], axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"Features shape:\", X.shape, \"| Target shape:\", y.shape)\n",
    "print(\"\\nMissing values in whole df:\", int(df.isna().sum().sum()))\n",
    "print(\"\\nTarget distribution (quality):\")\n",
    "print(y.value_counts().sort_index())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e72936",
   "metadata": {},
   "source": [
    "**Why this dataset works well with kNN (short rationale):**  \n",
    "Numeric features allow meaningful distances; the quality label provides a multi-class setup; and moderate size keeps training/testing fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f936c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1.2 First kNN run (Training) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96154aa5",
   "metadata": {},
   "source": [
    "**Goal (2/2 points):** Split 80/20 (stratified) and **train** baseline kNN (k=5). This cell **only trains** the model on the training set (no leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a69ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Re-split each run to be safe and reproducible; stratify keeps class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"| Test size:\", len(X_test))\n",
    "print(\"Model object:\", knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d966e2",
   "metadata": {},
   "source": [
    "### 1.2 First kNN run (Testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d4b6d",
   "metadata": {},
   "source": [
    "**Goal (2/2 points):** Predict on the held-out test set and report accuracy.  \n",
    "The cell below is **robust**: if the model `knn` isn't defined (e.g., kernel reset), it will re-train before predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a43240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ensure we have X, y; ensure we have a trained model\n",
    "try:\n",
    "    knn\n",
    "except NameError:\n",
    "    # re-split and re-train to avoid NameError if cells were run out of order\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = knn.predict(X_test)\n",
    "basic_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy (k=5) on test set:\", basic_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487c2d5",
   "metadata": {},
   "source": [
    "**Illustration: 80/20 split (conceptual)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddbb0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single illustrative plot (default style/colors)\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "grid = np.zeros((20, 6))\n",
    "grid[:16,:5] = 1   # train features\n",
    "grid[:16,5]  = 2   # train labels\n",
    "grid[16:,:5] = 3   # test features\n",
    "grid[16:,5]  = 4   # test labels\n",
    "\n",
    "plt.figure(figsize=(4,6))\n",
    "plt.imshow(grid, aspect='auto')\n",
    "plt.title('Example of 80/20 split')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19b38c",
   "metadata": {},
   "source": [
    "### 1.3 Listing of 2 more interresting use cases for kNN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71006a38",
   "metadata": {},
   "source": [
    "**Two real-world kNN use cases (done fully, 2/2 points)**  \n",
    "1) **Handwritten digit recognition (MNIST):** Classify digits (0–9) by comparing pixel vectors with nearest labeled examples. kNN is a clear baseline for image tasks.  \n",
    "2) **Customer similarity for marketing:** Find nearest customers by purchase/behavior vectors to enable look‑alike targeting and simple recommendations (items liked by neighbors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb901c",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7432af68",
   "metadata": {},
   "source": [
    "### 2.1 Experiments with different values of $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657ef6c",
   "metadata": {},
   "source": [
    "### 2.2 Studying the effect of different train/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e391a2",
   "metadata": {},
   "source": [
    "**Task (2/2 points):** Compare several **test sizes** (0.2, 0.3, 0.4) while keeping k=5 and present a tidy table with interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "split_sizes = [0.2, 0.3, 0.4]\n",
    "rows = []\n",
    "for s in split_sizes:\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=s, random_state=42, stratify=y)\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    pred = model.predict(X_te)\n",
    "    rows.append((s, accuracy_score(y_te, pred)))\n",
    "\n",
    "df_splits = pd.DataFrame(rows, columns=['test_size','test_accuracy']).sort_values('test_size')\n",
    "print(df_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00d799",
   "metadata": {},
   "source": [
    "**Analysis:** Accuracy varies with the amount of training data; 20% test split is a reasonable default. Cross‑validation (next) reduces dependence on a single split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb62ba5",
   "metadata": {},
   "source": [
    "### 2.3 $k$-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865240a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50d224b6",
   "metadata": {},
   "source": [
    "**Task (2/2 points):** Train kNN with multiple `k` values and compare **test accuracies** systematically; also show a simple accuracy‑vs‑k plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a55c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9, 11, 15]\n",
    "rows = []\n",
    "for k in k_values:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    rows.append((k, accuracy_score(y_test, pred)))\n",
    "\n",
    "df_k = pd.DataFrame(rows, columns=['k','test_accuracy']).sort_values('k')\n",
    "print(df_k)\n",
    "\n",
    "# Single plot, default style/colors\n",
    "plt.figure()\n",
    "plt.plot(df_k['k'], df_k['test_accuracy'], marker='o')\n",
    "plt.xlabel('k (neighbors)')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.title('kNN: accuracy vs k')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_idx = df_k['test_accuracy'].idxmax()\n",
    "best_k = int(df_k.loc[best_idx, 'k'])\n",
    "best_acc = float(df_k.loc[best_idx, 'test_accuracy'])\n",
    "print(f\"Best k on test set: k={best_k} with accuracy={best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc9ae54",
   "metadata": {},
   "source": [
    "**Analysis:** Small `k` may overfit noise; larger `k` smooths the decision boundary. Choose the `k` with highest accuracy; if tied, prefer a moderate `k` (5–7) for stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb173bc4",
   "metadata": {},
   "source": [
    "**Task (2/2 points):** Perform **5-fold cross‑validation** with k=5 and report the **average accuracy** with justification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "for tr_idx, te_idx in kf.split(X):\n",
    "    X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    preds = model.predict(X_te)\n",
    "    scores.append(accuracy_score(y_te, preds))\n",
    "\n",
    "cv_mean = sum(scores)/len(scores)\n",
    "print(\"5-fold CV mean accuracy:\", cv_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70358d5",
   "metadata": {},
   "source": [
    "**Justification & interpretation:** 5 folds balance stability and runtime for this dataset size. The CV mean is less sensitive to lucky/unlucky single splits and usually reflects generalization more reliably than one 80/20 result."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
